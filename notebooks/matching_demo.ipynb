{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# User Matching Experiment\n",
        "\n",
        "This experiment demonstrates how to compute a compatibility score between two users based on a shared conversation transcript.\n",
        "\n",
        "## Decision \n",
        "- **TF-IDF Vectorizer**: Good for vectorizing topics into numerical arrays\n",
        "- **Topic Weight**: 0.5, **Psychometrics Weight**: 1.0\n",
        "- **Compatibility Classes**: 7 levels (0.9/0.8/0.7/0.6/0.4/0.2/0.0)\n",
        "- **Data Preprocessing**: Normalization + Resampling for production robustness\n",
        "\n",
        "\n",
        "Method Choices\n",
        "1. **TF-IDF Vectorization**: Good to vectorize into an array of numbers\n",
        "2. **One-hot Encoding**: Producing only 0 and 1, better with categorical features and doesn't fit this task\n",
        "\n",
        "Weight Choices\n",
        "1. **Topic Weight** : 0.0 - 1.0, I chose 0.5 because users that listen to the same audio (only one audio/transcript here) may have a higher tendency to show compatibility\n",
        "2. **Psychometrics Weight** : 0.0 - 1.0, I chose 1.0 as personality is still a more dominant factor in my opinion \n",
        "\n",
        "Data Preprocessing\n",
        "1. **Normalization**: Min-max scaling to [0,1] range ensures fair comparison regardless of original data scales\n",
        "2. **Resampling**: Linear interpolation handles different psychometric vector lengths\n",
        "3. **Edge Case Handling**: Graceful handling of empty data, single values, and out-of-range inputs\n",
        "4. **Mathematical Stability**: Prevents division by zero and ensures valid [0,1] ranges\n",
        "\n",
        "Experiment Result (With v.s. without data processing)\n",
        "- **Original Score**: 0.699 (Moderately compatible - Decent match)\n",
        "- **Processed Score**: 0.516 (Somewhat compatible - Weak match)\n",
        "- **Difference**: 0.183 - The processed score is more accurate as it eliminates scale bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step1: Env Setup & Load Users\n",
        "\n",
        "**Observation**\n",
        "- From the raw data, a clear difference and be noticed, the difference between each trait range from 0.4 - 0.6\n",
        "    - traits = [openness, conscientiousness, extraversion, agreeableness, neuroticism]\n",
        "    - user_1 {'id': 'user_1', 'psychometrics': [0.8, 0.4, 0.7, 0.2, 0.9]}\n",
        "    - user_2 {'id': 'user_2', 'psychometrics': [0.3, 0.9, 0.1, 0.6, 0.4]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_1 {'id': 'user_1', 'psychometrics': [0.8, 0.4, 0.7, 0.2, 0.9]}\n",
            "user_2 {'id': 'user_2', 'psychometrics': [0.3, 0.9, 0.1, 0.6, 0.4]}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "\n",
        "USER_PATH = Path(\"../sample_data/synthetic_users.json\")\n",
        "\n",
        "with open(USER_PATH) as f:\n",
        "    users = json.load(f)\n",
        "\n",
        "user_1 = users[0]\n",
        "user_2 = users[1]\n",
        "print(\"user_1\", user_1)\n",
        "print(\"user_2\", user_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step2 : Vectorize the topics with TF-IDF\n",
        "\n",
        "**Note**\n",
        "1. KeyBERT are used to gives semantic keywords (strings), but no fixed-length vector\n",
        "2.\tTF-IDF allows us to **encode** these keywords numerically into a vector space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_1_topic_vec [0.447 0.447 0.447 0.447 0.447]\n",
            "user_2_topic_vec [0.447 0.447 0.447 0.447 0.447]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def vectorize_topics(topics, method='tfidf'):\n",
        "    # Convert list of topics into a single string per user\n",
        "    text = \" \".join(topics)\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vec = vectorizer.fit_transform([text])\n",
        "    return vec.toarray()[0]\n",
        "\n",
        "# Both users listened to the same transcript (topic_extraction_demo.ipynb)\n",
        "keybert_topics = ['starships', 'terraforming', 'scales', 'plan', 'synchronization']\n",
        "user_1_topic_vec = vectorize_topics(keybert_topics)\n",
        "user_2_topic_vec = vectorize_topics(keybert_topics)\n",
        "print(\"user_1_topic_vec\", user_1_topic_vec)\n",
        "print(\"user_2_topic_vec\", user_2_topic_vec)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation**\n",
        "- With only one transcript, the topic vector alone is not differentiating users\n",
        "- The psychometric weight is the key lever to demonstrate meaningful compatibility scores\n",
        "\n",
        "**Solution**\n",
        "- By adjusting w_topic and w_psych to control how much psychometrics vs topics contribute to the compatibility score in the next step\n",
        "\n",
        "    - w_psych >> w_topic → compatibility mostly reflects personality similarity\n",
        "    - w_topic >> w_psych → topics dominate (less meaningful here, since topics are identical)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step3: Combine with Psychometrics\n",
        "\n",
        "As discussed above, adjust the weights of topics and psychometrics (personality)\n",
        "\n",
        "I define the weights to be:\n",
        "- topic weights : 0.5, since users may share similar interests if they listen to the same audio (e.g. people with same interests tend to listen to the same podcast than others)\n",
        "- psychometrics weights : 1.0, since the personality is a more dominant factor to decide if people are able to get along"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_1_combined [0.224 0.224 0.224 0.224 0.224 0.8   0.4   0.7   0.2   0.9  ]\n",
            "user_2_combined [0.224 0.224 0.224 0.224 0.224 0.3   0.9   0.1   0.6   0.4  ]\n"
          ]
        }
      ],
      "source": [
        "def combine_vectors(topic_vec, psych_vec, topic_weight=1.0, psych_weight=1.0):\n",
        "    topic_vec = np.array(topic_vec)\n",
        "    psych_vec = np.array(psych_vec)\n",
        "    \n",
        "    # Scale vectors if needed\n",
        "    combined = np.concatenate([topic_weight * topic_vec, psych_weight * psych_vec])\n",
        "    return combined\n",
        "\n",
        "w_topic = 0.5  \n",
        "w_psych = 1.0  \n",
        "\n",
        "user_1_combined = combine_vectors(user_1_topic_vec, user_1[\"psychometrics\"], w_topic, w_psych)\n",
        "user_2_combined = combine_vectors(user_2_topic_vec, user_2[\"psychometrics\"], w_topic, w_psych)\n",
        "print(\"user_1_combined\", user_1_combined)\n",
        "print(\"user_2_combined\", user_2_combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step4: Compute Compatibility with Cosine Similarity\n",
        "\n",
        "Define 7 different classes\n",
        "- Perfect Match: > 0.9\n",
        "- Strong Match: > 0.8\n",
        "- Good Match: > 0.7\n",
        "- Decent Match: > 0.6\n",
        "- Weak Match: > 0.4\n",
        "- Poor Match: > 0.2\n",
        "- Minimal Match: else"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compatibility Score: 0.699\n",
            "Interpretation: Moderately compatible - Decent match\n"
          ]
        }
      ],
      "source": [
        "def interpret_score(score):\n",
        "    if score >= 0.9:\n",
        "        return \"Exceptionally compatible - Perfect match\"\n",
        "    elif score >= 0.8:\n",
        "        return \"Highly compatible - Strong match\"\n",
        "    elif score >= 0.7:\n",
        "        return \"Very compatible - Good match\"\n",
        "    elif score >= 0.6:\n",
        "        return \"Moderately compatible - Decent match\"\n",
        "    elif score >= 0.4:\n",
        "        return \"Somewhat compatible - Weak match\"\n",
        "    elif score >= 0.2:\n",
        "        return \"Low compatibility - Poor match\"\n",
        "    else:\n",
        "        return \"Very low compatibility - Minimal match\"\n",
        "    \n",
        "\n",
        "def compute_compatibility(vec1, vec2):\n",
        "    score = cosine_similarity([vec1], [vec2])[0][0]\n",
        "    interpretation = interpret_score(score)\n",
        "    return score, interpretation\n",
        "\n",
        "score, interpretation = compute_compatibility(user_1_combined, user_2_combined)\n",
        "\n",
        "\n",
        "print(f\"Compatibility Score: {score:.3f}\")\n",
        "print(f\"Interpretation: {interpretation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation**\n",
        "- Since both users share the same transcript topics only a smaller weight (0.2) is applied, the differentiating factor comes primarily from their psychometric vectors, so a higher weight (1.0) is used to distinguish them\n",
        "- From the raw data, the difference between each trait range from 0.4 - 0.6, which is around low to moderate\n",
        "- Considering the fact that both users listened to the same audio, they have smiliar interest, therefore, the final compatibility score increases after the adjustment of topic weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step5: Experiment: Normalization & Resampling\n",
        "\n",
        "#### Normalization\n",
        "- Consistent data range : [0, 1] range using **min-max** scaling\n",
        "- Handles edge cases (all same values, zero variance)\n",
        "- Returns neutral values (0.5) for constant data\n",
        "\n",
        "#### Resampling\n",
        "- Flexible vector lengths : Handles different psychometric vector lengths\n",
        "- Uses linear interpolation for smooth resampling\n",
        "- Handles edge cases (empty data, single values)\n",
        "- Returns neutral values (0.5) for empty data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_psychometrics(psychometric_data: list[float]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Normalize psychometric data to [0, 1] range\n",
        "    Handles cases where data might be outside expected range\n",
        "    \"\"\"\n",
        "    psych_array = np.array(psychometric_data)\n",
        "    \n",
        "    # Handle all same values\n",
        "    if np.all(psych_array == psych_array[0]):\n",
        "        return np.full_like(psych_array, 0.5)\n",
        "    \n",
        "    # Min-max normalization to [0, 1]\n",
        "    min_val = np.min(psych_array)\n",
        "    max_val = np.max(psych_array)\n",
        "    \n",
        "    if max_val == min_val:\n",
        "        return np.full_like(psych_array, 0.5)\n",
        "    \n",
        "    normalized = (psych_array - min_val) / (max_val - min_val)\n",
        "    return np.clip(normalized, 0.0, 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Testing Normalization ===\n",
            "Original user_1 psychometrics: [0.8, 0.4, 0.7, 0.2, 0.9]\n",
            "Original user_2 psychometrics: [0.3, 0.9, 0.1, 0.6, 0.4]\n",
            "Normalized user_1: [0.857 0.286 0.714 0.    1.   ]\n",
            "Normalized user_2: [0.25  1.    0.    0.625 0.375]\n",
            "\n",
            "=== Testing Edge Cases ===\n",
            "Out of range [2.5, -0.3, 1.8, 0.1, 3.0]\n",
            "normalized: [0.848 0.    0.636 0.121 1.   ]\n"
          ]
        }
      ],
      "source": [
        "# Test the normalization and resampling functions\n",
        "print(\"=== Testing Normalization ===\")\n",
        "\n",
        "# Test with original psychometric data\n",
        "user1_psych_raw = user_1[\"psychometrics\"]\n",
        "user2_psych_raw = user_2[\"psychometrics\"]\n",
        "\n",
        "print(f\"Original user_1 psychometrics: {user1_psych_raw}\")\n",
        "print(f\"Original user_2 psychometrics: {user2_psych_raw}\")\n",
        "\n",
        "# Normalize the data\n",
        "user1_psych_normalized = normalize_psychometrics(user1_psych_raw)\n",
        "user2_psych_normalized = normalize_psychometrics(user2_psych_raw)\n",
        "\n",
        "print(f\"Normalized user_1: {user1_psych_normalized}\")\n",
        "print(f\"Normalized user_2: {user2_psych_normalized}\")\n",
        "\n",
        "# Test edge cases\n",
        "print(\"\\n=== Testing Edge Cases ===\")\n",
        "# Test with data outside [0,1] range\n",
        "out_of_range = [2.5, -0.3, 1.8, 0.1, 3.0]\n",
        "normalized_out = normalize_psychometrics(out_of_range)\n",
        "print(f\"Out of range {out_of_range}\")\n",
        "print(f\"normalized: {normalized_out}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resample_psychometrics(psychometric_data: list[float], target_length: int = 5) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Resample psychometric data to target length using interpolation\n",
        "    Handles cases where psychometric vectors have different lengths\n",
        "    \"\"\"\n",
        "    psych_array = np.array(psychometric_data)\n",
        "    current_length = len(psych_array)\n",
        "    \n",
        "    if current_length == target_length:\n",
        "        return psych_array\n",
        "    \n",
        "    if current_length == 0:\n",
        "        # Return neutral values if no data\n",
        "        return np.full(target_length, 0.5)\n",
        "    \n",
        "    if current_length == 1:\n",
        "        # Replicate single value\n",
        "        return np.full(target_length, psych_array[0])\n",
        "    \n",
        "    # Use linear interpolation to resample\n",
        "    x_old = np.linspace(0, 1, current_length)\n",
        "    x_new = np.linspace(0, 1, target_length)\n",
        "    \n",
        "    resampled = np.interp(x_new, x_old, psych_array)\n",
        "    return resampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Target length 3:\n",
            "  user_1 resampled: [0.857 0.714 1.   ]\n",
            "  user_2 resampled: [0.25  0.    0.375]\n",
            "\n",
            "Target length 5:\n",
            "  user_1 resampled: [0.857 0.286 0.714 0.    1.   ]\n",
            "  user_2 resampled: [0.25  1.    0.    0.625 0.375]\n",
            "\n",
            "Target length 7:\n",
            "  user_1 resampled: [0.857 0.476 0.429 0.714 0.238 0.333 1.   ]\n",
            "  user_2 resampled: [0.25  0.75  0.667 0.    0.417 0.542 0.375]\n",
            "\n",
            "Target length 10:\n",
            "  user_1 resampled: [0.857 0.603 0.349 0.429 0.619 0.556 0.238 0.111 0.556 1.   ]\n",
            "  user_2 resampled: [0.25  0.583 0.917 0.667 0.222 0.139 0.417 0.597 0.486 0.375]\n",
            "\n",
            "=== Testing Edge Cases ===\n",
            "All same values [0.5, 0.5, 0.5, 0.5, 0.5]\n",
            "normalized: [0.5 0.5 0.5 0.5 0.5]\n",
            "Empty data resampled to length 5: [0.5 0.5 0.5 0.5 0.5]\n",
            "Single value [0.8] resampled to length 5: [0.8 0.8 0.8 0.8 0.8]\n"
          ]
        }
      ],
      "source": [
        "# Test resampling with different target lengths\n",
        "target_lengths = [3, 5, 7, 10]\n",
        "\n",
        "for target_len in target_lengths:\n",
        "    user1_resampled = resample_psychometrics(user1_psych_normalized, target_len)\n",
        "    user2_resampled = resample_psychometrics(user2_psych_normalized, target_len)\n",
        "    \n",
        "    print(f\"\\nTarget length {target_len}:\")\n",
        "    print(f\"  user_1 resampled: {user1_resampled}\")\n",
        "    print(f\"  user_2 resampled: {user2_resampled}\")\n",
        "\n",
        "# Test edge cases\n",
        "print(\"\\n=== Testing Edge Cases ===\")\n",
        "\n",
        "# Test with all same values\n",
        "same_values = [0.5, 0.5, 0.5, 0.5, 0.5]\n",
        "normalized_same = normalize_psychometrics(same_values)\n",
        "print(f\"All same values {same_values}\")\n",
        "print(f\"normalized: {normalized_same}\")\n",
        "\n",
        "# Test with empty data\n",
        "empty_data = []\n",
        "resampled_empty = resample_psychometrics(empty_data, 5)\n",
        "print(f\"Empty data resampled to length 5: {resampled_empty}\")\n",
        "\n",
        "# Test with single value\n",
        "single_value = [0.8]\n",
        "resampled_single = resample_psychometrics(single_value, 5)\n",
        "print(f\"Single value {single_value} resampled to length 5: {resampled_single}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Matching with Normalization and Resampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed user_1 psychometrics: [0.857 0.286 0.714 0.    1.   ]\n",
            "Processed user_2 psychometrics: [0.25  1.    0.    0.625 0.375]\n",
            "\n",
            "Combined vectors (with processed psychometrics):\n",
            "user_1_combined: [0.224 0.224 0.224 0.224 0.224 0.857 0.286 0.714 0.    1.   ]\n",
            "user_2_combined: [0.224 0.224 0.224 0.224 0.224 0.25  1.    0.    0.625 0.375]\n",
            "\n",
            "=== RESULTS ===\n",
            "Original Score: 0.699 - Moderately compatible - Decent match\n",
            "Processed Score: 0.516 - Somewhat compatible - Weak match\n",
            "Difference: 0.183\n"
          ]
        }
      ],
      "source": [
        "from regex.regex import U\n",
        "\n",
        "\n",
        "def test_matching_with_processing(user1_data, user2_data, topics, w_topic=0.5, w_psych=1.0, target_length=5):\n",
        "    # Process psychometric data\n",
        "    user1_psych_processed = resample_psychometrics(normalize_psychometrics(user1_data), target_length)\n",
        "    user2_psych_processed = resample_psychometrics(normalize_psychometrics(user2_data), target_length)\n",
        "    \n",
        "    print(f\"Processed user_1 psychometrics: {user1_psych_processed}\")\n",
        "    print(f\"Processed user_2 psychometrics: {user2_psych_processed}\")\n",
        "    \n",
        "    # Vectorize topics\n",
        "    user_1_topic_vec = vectorize_topics(topics)\n",
        "    user_2_topic_vec = vectorize_topics(topics)\n",
        "    \n",
        "    # Combine vectors with processed psychometric data\n",
        "    user_1_combined_processed = combine_vectors(user_1_topic_vec, user1_psych_processed, w_topic, w_psych)\n",
        "    user_2_combined_processed = combine_vectors(user_2_topic_vec, user2_psych_processed, w_topic, w_psych)\n",
        "    \n",
        "    print(f\"\\nCombined vectors (with processed psychometrics):\")\n",
        "    print(f\"user_1_combined: {user_1_combined_processed}\")\n",
        "    print(f\"user_2_combined: {user_2_combined_processed}\")\n",
        "    \n",
        "    # Compute compatibility with processed data\n",
        "    score_processed, interpretation_processed = compute_compatibility(user_1_combined_processed, user_2_combined_processed)\n",
        "    \n",
        "    # Compare with original (unprocessed) results\n",
        "    user_1_combined_original = combine_vectors(user_1_topic_vec, user1_data, w_topic, w_psych)\n",
        "    user_2_combined_original = combine_vectors(user_2_topic_vec, user2_data, w_topic, w_psych)\n",
        "    score_original, interpretation_original = compute_compatibility(user_1_combined_original, user_2_combined_original)\n",
        "    \n",
        "    print(f\"\\n=== RESULTS ===\")\n",
        "    print(f\"Original Score: {score_original:.3f} - {interpretation_original}\")\n",
        "    print(f\"Processed Score: {score_processed:.3f} - {interpretation_processed}\")\n",
        "    print(f\"Difference: {abs(score_processed - score_original):.3f}\")\n",
        "    \n",
        "    return {\n",
        "        'original_score': score_original,\n",
        "        'processed_score': score_processed,\n",
        "        'difference': abs(score_processed - score_original),\n",
        "        'processed_psychometrics': {\n",
        "            'user1': user1_psych_processed,\n",
        "            'user2': user2_psych_processed\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Test with our own example data\n",
        "keybert_topics = ['starships', 'terraforming', 'scales', 'plan', 'synchronization']\n",
        "results = test_matching_with_processing(\n",
        "    user1_data=user_1[\"psychometrics\"],\n",
        "    user2_data=user_2[\"psychometrics\"], \n",
        "    topics=keybert_topics,\n",
        "    w_topic=0.5,\n",
        "    w_psych=1.0,\n",
        "    target_length=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation**\n",
        "\n",
        "The score with normalization and resampling (0.516) is lower than original (0.699)\n",
        "\n",
        "Reason\n",
        "1. Data Quality Improvement\n",
        "    - Original: Inconsistent scales and ranges between users\n",
        "    - Processed: Normalized to [0,1] range ensures fair comparison\n",
        "    - Result: Eliminates scale bias that inflated the original score\n",
        "\n",
        "2. Reveals True Personality Differences\n",
        "    - Original: [0.8, 0.4, 0.7, 0.2, 0.9] vs [0.3, 0.9, 0.1, 0.6, 0.4]\n",
        "    - Processed: [0.857, 0.286, 0.714, 0.000, 1.000] vs [0.250, 1.000, 0.000, 0.625, 0.375]\n",
        "    - Result: Shows more extreme differences, revealing true incompatibility\n",
        "\n",
        "\n",
        "**Conclusion**: The processed score of 0.516 (\"Somewhat compatible - Weak match\") is more accurate and trustworthy than the original 0.699 (\"Moderately compatible - Decent match\") because it accounts for data quality issues and reveals true personality compatibility, and because the original personality difference range from 0.4-0.6."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
