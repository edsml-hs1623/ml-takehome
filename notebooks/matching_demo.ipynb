{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# User Matching Experiment\n",
        "\n",
        "This experiment demonstrates how to compute a compatibility score between two users based on a shared conversation transcript.\n",
        "\n",
        "## Decision \n",
        "- TF-IDF Vectorizer\n",
        "- Topic Weight : 0.5, Psychometrics Weight : 1.0\n",
        "- Compatibility Classes: High / Moderate / Low (0.8/0.5/0.0) \n",
        "\n",
        "Method Choices\n",
        "1. TF-IDF Vectorization : good to vectorize into an array of numbers\n",
        "2. One-hot Encoding : producing only 0 and 1, better with categorical features and doesn't fit this task\n",
        "\n",
        "Weight Choices\n",
        "1. Topic Weight : 0.0 - 1.0, I chose 0.5 because users that listen to the same audio (only one audio/transcript here) may have a higher tendency to show compatibility\n",
        "2. Psychometrics weight : 0.0 - 1.0, I chose 1.0 as personality is still a more dominant factor in my opinion "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step1: Env Setup & Load Users\n",
        "\n",
        "**Observation**\n",
        "- From the raw data, a clear difference and be noticed, the difference between each trait range from 0.4 - 0.6\n",
        "    - traits = [openness, conscientiousness, extraversion, agreeableness, neuroticism]\n",
        "    - user_1 {'id': 'user_1', 'psychometrics': [0.8, 0.4, 0.7, 0.2, 0.9]}\n",
        "    - user_2 {'id': 'user_2', 'psychometrics': [0.3, 0.9, 0.1, 0.6, 0.4]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_1 {'id': 'user_1', 'psychometrics': [0.8, 0.4, 0.7, 0.2, 0.9]}\n",
            "user_2 {'id': 'user_2', 'psychometrics': [0.3, 0.9, 0.1, 0.6, 0.4]}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "USER_PATH = Path(\"../sample_data/synthetic_users.json\")\n",
        "\n",
        "with open(USER_PATH) as f:\n",
        "    users = json.load(f)\n",
        "\n",
        "user_1 = users[0]\n",
        "user_2 = users[1]\n",
        "print(\"user_1\", user_1)\n",
        "print(\"user_2\", user_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step2 : Vectorize the topics with TF-IDF\n",
        "\n",
        "**Note**\n",
        "1. KeyBERT are used to gives semantic keywords (strings), but no fixed-length vector\n",
        "2.\tTF-IDF allows us to **encode** these keywords numerically into a vector space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_1_topic_vec [0.4472136 0.4472136 0.4472136 0.4472136 0.4472136]\n",
            "user_2_topic_vec [0.4472136 0.4472136 0.4472136 0.4472136 0.4472136]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def vectorize_topics(topics, method='tfidf'):\n",
        "    # Convert list of topics into a single string per user\n",
        "    text = \" \".join(topics)\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vec = vectorizer.fit_transform([text])\n",
        "    return vec.toarray()[0]\n",
        "\n",
        "# Both users listened to the same transcript (topic_extraction_demo.ipynb)\n",
        "keybert_topics = ['starships', 'terraforming', 'scales', 'plan', 'synchronization']\n",
        "user_1_topic_vec = vectorize_topics(keybert_topics)\n",
        "user_2_topic_vec = vectorize_topics(keybert_topics)\n",
        "print(\"user_1_topic_vec\", user_1_topic_vec)\n",
        "print(\"user_2_topic_vec\", user_2_topic_vec)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation**\n",
        "- With only one transcript, the topic vector alone is not differentiating users\n",
        "- The psychometric weight is the key lever to demonstrate meaningful compatibility scores\n",
        "\n",
        "**Solution**\n",
        "- By adjusting w_topic and w_psych to control how much psychometrics vs topics contribute to the compatibility score in the next step\n",
        "\n",
        "    - w_psych >> w_topic → compatibility mostly reflects personality similarity\n",
        "    - w_topic >> w_psych → topics dominate (less meaningful here, since topics are identical)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step3: Combine with Psychometrics\n",
        "\n",
        "As discussed above, adjust the weights of topics and psychometrics (personality)\n",
        "\n",
        "I define the weights to be:\n",
        "- topic weights : 0.5, since users may share similar interests if they listen to the same audio (e.g. people with same interests tend to listen to the same podcast than others)\n",
        "- psychometrics weights : 1.0, since the personality is a more dominant factor to decide if people are able to get along"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_1_combined [0.2236068 0.2236068 0.2236068 0.2236068 0.2236068 0.8       0.4\n",
            " 0.7       0.2       0.9      ]\n",
            "user_2_combined [0.2236068 0.2236068 0.2236068 0.2236068 0.2236068 0.3       0.9\n",
            " 0.1       0.6       0.4      ]\n"
          ]
        }
      ],
      "source": [
        "def combine_vectors(topic_vec, psych_vec, topic_weight=1.0, psych_weight=1.0):\n",
        "    topic_vec = np.array(topic_vec)\n",
        "    psych_vec = np.array(psych_vec)\n",
        "    \n",
        "    # Scale vectors if needed\n",
        "    combined = np.concatenate([topic_weight * topic_vec, psych_weight * psych_vec])\n",
        "    return combined\n",
        "\n",
        "w_topic = 0.5  \n",
        "w_psych = 1.0  \n",
        "\n",
        "user_1_combined = combine_vectors(user_1_topic_vec, user_1[\"psychometrics\"], w_topic, w_psych)\n",
        "user_2_combined = combine_vectors(user_2_topic_vec, user_2[\"psychometrics\"], w_topic, w_psych)\n",
        "print(\"user_1_combined\", user_1_combined)\n",
        "print(\"user_2_combined\", user_2_combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step4: Compute Compatibility with Cosine Similarity\n",
        "\n",
        "Define different classes\n",
        "- High : 1.0 score > 0.8\n",
        "- Moderate : 0.8 > score > 0.5\n",
        "- Low : 0.5 > score > 0.0 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compatibility Score: 0.699\n",
            "Interpretation: Moderately compatible\n"
          ]
        }
      ],
      "source": [
        "def compute_compatibility(vec1, vec2):\n",
        "    score = cosine_similarity([vec1], [vec2])[0][0]\n",
        "    \n",
        "    # Simple interpretation\n",
        "    if score > 0.8:\n",
        "        interpretation = \"Highly compatible\"\n",
        "    elif score > 0.5:\n",
        "        interpretation = \"Moderately compatible\"\n",
        "    else:\n",
        "        interpretation = \"Low compatibility\"\n",
        "    \n",
        "    return score, interpretation\n",
        "\n",
        "score, interpretation = compute_compatibility(user_1_combined, user_2_combined)\n",
        "\n",
        "print(f\"Compatibility Score: {score:.3f}\")\n",
        "print(f\"Interpretation: {interpretation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation**\n",
        "- Since both users share the same transcript topics only a smaller weight (0.2) is applied, the differentiating factor comes primarily from their psychometric vectors, so a higher weight (1.0) is used to distinguish them\n",
        "- From the raw data, the difference between each trait range from 0.4 - 0.6, which is around low to moderate\n",
        "- Considering the fact that both users listened to the same audio, they have smiliar interest, therefore, the final compatibility score increases after the adjustment of topic weights\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
